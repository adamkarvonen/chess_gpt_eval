{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # For testing: Create a small df\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('mac_dataset.csv')\n",
    "\n",
    "# # Randomly sample 10000 rows\n",
    "# sampled_df = df.sample(n=10000)\n",
    "\n",
    "# # Sort the sampled DataFrame by the length of the 'transcript' column\n",
    "# # sampled_df.sort_values(by='transcript', key=lambda x: x.str.len(), ascending=True, inplace=True)\n",
    "\n",
    "# # Save the sampled and sorted DataFrame to a new CSV file\n",
    "# sampled_df.to_csv('test_input_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "before: 10344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/10344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 10344/10344 [00:00<00:00, 20883.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after: 10344\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "input_file = 'mac_dataset.csv'\n",
    "input_file = 'test_input_dataset.csv'\n",
    "\n",
    "def dedup_dataset(input_file: str):\n",
    "# Step 1: Deduplicate games\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    unique_transcripts = set()\n",
    "    rows_to_delete = []\n",
    "\n",
    "    print(f\"before: {len(df)}\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        transcript = row['transcript']\n",
    "        if transcript not in unique_transcripts:\n",
    "            unique_transcripts.add(transcript)\n",
    "        else:\n",
    "            rows_to_delete.append(index)\n",
    "\n",
    "    df.drop(rows_to_delete, inplace=True)\n",
    "\n",
    "    print(f\"after: {len(df)}\")\n",
    "\n",
    "    df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Step 2: Add player skill to beginning of every transcript\n",
    "# At the end of this, we will save only the 'transcript' column to 'input_dataset.csv', as other info is no longer needed\n",
    "\n",
    "def map_skill_to_int(skill: int) -> str:\n",
    "    if skill == 20:\n",
    "        return '9'\n",
    "    if random.random() > 0.5:\n",
    "        return '?'\n",
    "    if skill == -2:\n",
    "        return '0'\n",
    "    # Define the original and target ranges\n",
    "    original_min, original_max = -1, 19\n",
    "    target_min, target_max = 1, 8\n",
    "\n",
    "    # Calculate the total number of values in each range\n",
    "    original_range = original_max - original_min\n",
    "    target_range = target_max - target_min\n",
    "\n",
    "    # Scale the original value to the target range\n",
    "    scaled_value = ((skill - original_min) / original_range) * target_range + target_min\n",
    "\n",
    "    # Round and return the scaled value, making sure it stays within the target range\n",
    "    return str(min(target_max, max(target_min, round(scaled_value))))\n",
    "\n",
    "def transform_row(row):\n",
    "    # Split and get the number from player_one and player_two\n",
    "    player_one_number = int(row['player_one'].split()[1])\n",
    "    player_two_number = int(row['player_two'].split()[1])\n",
    "\n",
    "    # Apply map_value to these numbers\n",
    "    mapped_player_one = map_skill_to_int(player_one_number)\n",
    "    mapped_player_two = map_skill_to_int(player_two_number)\n",
    "\n",
    "    transcript = row['transcript'].split('\\n\\n')[1]\n",
    "\n",
    "    # Prepend the transcript with the formatted string\n",
    "    row['transcript'] = f\"[{mapped_player_one},{mapped_player_two}]{transcript}\"\n",
    "\n",
    "    return row\n",
    "\n",
    "# skills = range(-2,21)\n",
    "\n",
    "# for skill in skills:\n",
    "#     print(skill, map_skill_to_int(skill))\n",
    "# df_subset = df.sample(10)\n",
    "# df_transformed = df_subset.apply(transform_row, axis=1)\n",
    "# print(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04df2ea6a9974f23aae006f7b6ed7073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(input_file)\n",
    "df = df.parallel_apply(transform_row, axis=1)\n",
    "df['transcript'].to_csv('input_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from stockfish import Stockfish\n",
    "import random\n",
    "\n",
    "# Step 3: Randomly insert centipawn\n",
    "def map_eval_to_int(evaluation: dict) -> int:\n",
    "    if evaluation['type'] == 'mate':\n",
    "        # for example, 3 would be mate in 3 for white, -2 is mate in 2 for black\n",
    "        if evaluation['value'] > 0:\n",
    "            return 9\n",
    "        else:\n",
    "            return -9\n",
    "    \n",
    "    # if not mate, must be centipawn advantage\n",
    "    value = evaluation['value']\n",
    "\n",
    "    if value > 700:\n",
    "        return 8\n",
    "    elif value < -700:\n",
    "        return -8\n",
    "    original_min, original_max = -700, 700\n",
    "    target_min, target_max = -7, 7\n",
    "\n",
    "    # Calculate the total number of values in each range\n",
    "    original_range = original_max - original_min\n",
    "    target_range = target_max - target_min\n",
    "\n",
    "    # Scale the original value to the target range\n",
    "    scaled_value = ((value - original_min) / original_range) * target_range + target_min\n",
    "\n",
    "    # Round and return the scaled value, making sure it stays within the target range\n",
    "    return str(min(target_max, max(target_min, round(scaled_value))))\n",
    "    \n",
    "def game_over_to_value(board_result: str) -> int:\n",
    "    result_map = {\"1-0\": 9, \"0-1\": -9, \"1/2-1/2\": 0}\n",
    "    return result_map[board_result]\n",
    "\n",
    "def insert_centipawn(moves_string: str, depth: int = 9, frequency: float = 0.03) -> str:\n",
    "    # Create a new board\n",
    "    board = chess.Board()\n",
    "\n",
    "    mac_path = \"stockfish\"\n",
    "    linux_path = \"/usr/games/stockfish\"\n",
    "    # self._engine = chess.engine.SimpleEngine.popen_uci(linux_path)\n",
    "    stockfish = Stockfish(mac_path)\n",
    "    stockfish.set_depth(depth) \n",
    "    eval_results = []\n",
    "\n",
    "    new_moves_string = \"\"\n",
    "\n",
    "    # Apply each move to the board\n",
    "    for move in moves_string.split():\n",
    "        # Skip move numbers\n",
    "        if '.' in move:\n",
    "            board.push_san(move.split(\".\")[1])\n",
    "        else:\n",
    "            board.push_san(move)\n",
    "\n",
    "        new_moves_string += move + \" \"\n",
    "        if random.random() < frequency:\n",
    "            # Check for checkmate or draw\n",
    "            eval = \"\"\n",
    "            if board.result() != \"*\":\n",
    "                # eval_results.append(game_over_to_value(board.result()))\n",
    "                eval = \" <\" + str(game_over_to_value(board.result())) + \"> \"\n",
    "            else:\n",
    "                stockfish.set_fen_position(board.fen())\n",
    "                evaluation = stockfish.get_evaluation()\n",
    "\n",
    "                # eval_results.append(map_eval_to_int(evaluation))\n",
    "                eval = \"<\" + str(map_eval_to_int(evaluation)) + \" \"\n",
    "\n",
    "            new_moves_string += eval\n",
    "\n",
    "    # Display the board position after the moves\n",
    "    # print(board.result())\n",
    "\n",
    "    # return eval_results\n",
    "    return new_moves_string\n",
    "\n",
    "# your_list = range(-800, 800, 40)\n",
    "# mapped_list = [map_eval_to_int({\"type\":\"cp\", \"value\":x}) for x in your_list]\n",
    "\n",
    "# for i in range(len(mapped_list)):\n",
    "#     print(mapped_list[i], your_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing centipawn\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(input_file)\n",
    "# index = 1\n",
    "# selected_rows = df.groupby('result').first().reset_index()\n",
    "# selected_rows = selected_rows.apply(transform_row, axis=1)\n",
    "# print(selected_rows.iloc[index]['transcript'])\n",
    "# selected_rows['transcript'] = selected_rows['transcript'].apply(lambda x: insert_centipawn(x, depth=10))\n",
    "\n",
    "\n",
    "# For graphing results\n",
    "\n",
    "# print(selected_rows.iloc[index]['transcript'])\n",
    "# print(selected_rows.iloc[index])\n",
    "\n",
    "# new_moves = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=10)\n",
    "# print(new_moves)\n",
    "\n",
    "# Make insert centipawn return list to graph evals\n",
    "# ten = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=10)\n",
    "# nine = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=9)\n",
    "# ten = [int(i) for i in ten]\n",
    "# nine = [int(i) for i in nine]\n",
    "\n",
    "\n",
    "# plt.plot(ten, label='ten', color='blue')\n",
    "# plt.plot(nine, color='red')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c4a27ee2c24af6a323a533119c31c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('input_dataset.csv')\n",
    "df['transcript'] = df['transcript'].parallel_apply(lambda x: insert_centipawn(x, depth=10, frequency=0.03))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text: str) -> list[str]:\n",
    "    full_chunk_size = 1023\n",
    "    header_size = 5\n",
    "    chunk_size = full_chunk_size - header_size\n",
    "\n",
    "    length = len(text)\n",
    "\n",
    "    if length < full_chunk_size:\n",
    "        return text\n",
    "    \n",
    "    header = text[:header_size]\n",
    "\n",
    "    text = text[header_size:]\n",
    "    length = len(text)\n",
    "\n",
    "    # Calculate the number of chunks needed\n",
    "    num_chunks = (length + chunk_size - 1) // chunk_size\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start_index = length - (i + 1) * chunk_size\n",
    "        end_index = length - i * chunk_size\n",
    "        start_index = max(start_index, 0)  # Ensure the start index is not negative\n",
    "\n",
    "        chunk = header + text[start_index:end_index]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Reverse the list to maintain the chronological order\n",
    "    chunks.reverse()\n",
    "\n",
    "    if len(chunks[0]) < 511:\n",
    "        chunks.pop(0)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e768cfd8746e7869a19e8e31640b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['transcript'] = df['transcript'].parallel_apply(transform_text)\n",
    "df = df.explode('transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10344\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.to_csv('input_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # For testing transform text\n",
    "\n",
    "# df = pd.read_csv(input_file)\n",
    "# df = df.apply(transform_row, axis=1)\n",
    "\n",
    "# filtered_df = df[df['transcript'].apply(len) > 2500]\n",
    "\n",
    "# text = filtered_df.iloc[0]['transcript']\n",
    "\n",
    "# print(len(df))\n",
    "# print(len(filtered_df))\n",
    "# print(len(filtered_df)/len(df))\n",
    "\n",
    "# chunks = transform_text(text)\n",
    "# text1 = chunks[0]\n",
    "\n",
    "# for chunk in chunks:\n",
    "#     print(len(chunk))\n",
    "#     print(chunk)\n",
    "\n",
    "# chunks2 = transform_text(text1)\n",
    "# print(len(chunks2))\n",
    "# print(chunks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f625f4a600e47ed81c02ff39272b942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1293), Label(value='0 / 1293'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sort df by transcript length for batching\n",
    "\n",
    "df = pd.read_csv('input_dataset.csv', usecols=['transcript'])\n",
    "df['length'] = df['transcript'].parallel_apply(len)\n",
    "\n",
    "df.sort_values(by='length', inplace=True)\n",
    "# df.to_csv('input_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = input_file.replace('.csv', '_blocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10344/10344 [00:00<00:00, 386349.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import random\n",
    "\n",
    "# Read the CSV file\n",
    "# df = pd.read_csv('input_dataset.csv')\n",
    "\n",
    "# Prepare the new dataset for blocks\n",
    "blocks = []\n",
    "remaining_games = deque(df['transcript'].tolist())  # Use deque for efficient pops from the left\n",
    "\n",
    "original_length = len(remaining_games)  # Store the original length\n",
    "\n",
    "# Block size limit\n",
    "block_size = 1024\n",
    "\n",
    "# Initialize the progress bar\n",
    "with tqdm(total=original_length, desc=\"Processing\") as pbar:\n",
    "    while remaining_games:\n",
    "        block = ';'\n",
    "        # Select the next game\n",
    "        next_game = remaining_games.pop()\n",
    "        block += next_game\n",
    "        while len(block) < block_size and remaining_games:\n",
    "            # if len(df) > 21:\n",
    "            #     random_idx = random.randint(0, 20)\n",
    "            #     next_game = remaining_games[random_idx]\n",
    "            #     remaining_games[random_idx] = \"\"\n",
    "            # else:\n",
    "            next_game = remaining_games.popleft()\n",
    "            block += ';' + next_game\n",
    "            if len(block) > block_size:\n",
    "                # If the game makes the block too long, re-add it to the dataset\n",
    "                if len(remaining_games) > 100:\n",
    "                    remaining_games.insert(99, next_game)\n",
    "                else:\n",
    "                    break\n",
    "                break\n",
    "\n",
    "        if len(block) >= block_size:\n",
    "            # Add the block to the blocks list\n",
    "            blocks.append(block[:block_size])\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(original_length - len(remaining_games) - pbar.n)\n",
    "\n",
    "# Create a new DataFrame for the blocks\n",
    "blocks_df = pd.DataFrame(blocks, columns=['transcript'])\n",
    "\n",
    "# Save the blocks to a new CSV file\n",
    "blocks_df.to_csv(output_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7199.0\n",
      "mean     1024.0\n",
      "std         0.0\n",
      "min      1024.0\n",
      "25%      1024.0\n",
      "50%      1024.0\n",
      "75%      1024.0\n",
      "max      1024.0\n",
      "Name: length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(output_filename)\n",
    "df['length'] = df['transcript'].apply(len)\n",
    "print(df['length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Shuffle dataset\n",
    "\n",
    "temp_output_filename = \"full2_dataset.csv\"\n",
    "# output_filename = temp_output_filename\n",
    "\n",
    "df = pd.read_csv(output_filename)\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the shuffled DataFrame to the same CSV file\n",
    "df_shuffled.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
