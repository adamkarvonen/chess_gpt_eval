{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # For testing: Create a small df\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('mac_dataset.csv')\n",
    "\n",
    "# # Randomly sample 10000 rows\n",
    "# sampled_df = df.sample(n=10000)\n",
    "\n",
    "# # Sort the sampled DataFrame by the length of the 'transcript' column\n",
    "# # sampled_df.sort_values(by='transcript', key=lambda x: x.str.len(), ascending=True, inplace=True)\n",
    "\n",
    "# # Save the sampled and sorted DataFrame to a new CSV file\n",
    "# sampled_df.to_csv('test_input_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "input_file = 'mac_dataset.csv'\n",
    "input_file = 'test_input_dataset.csv'\n",
    "\n",
    "def dedup_dataset(input_file: str):\n",
    "# Step 1: Deduplicate games\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    unique_transcripts = set()\n",
    "    rows_to_delete = []\n",
    "\n",
    "    print(f\"before: {len(df)}\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        transcript = row['transcript']\n",
    "        if transcript not in unique_transcripts:\n",
    "            unique_transcripts.add(transcript)\n",
    "        else:\n",
    "            rows_to_delete.append(index)\n",
    "\n",
    "    df.drop(rows_to_delete, inplace=True)\n",
    "\n",
    "    print(f\"after: {len(df)}\")\n",
    "\n",
    "    df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Step 2: Add player skill to beginning of every transcript\n",
    "# At the end of this, we will save only the 'transcript' column to 'input_dataset.csv', as other info is no longer needed\n",
    "\n",
    "def map_skill_to_int(skill: int) -> str:\n",
    "    if skill == 20:\n",
    "        return '9'\n",
    "    if random.random() > 0.5:\n",
    "        return '?'\n",
    "    if skill == -2:\n",
    "        return '0'\n",
    "    # Define the original and target ranges\n",
    "    original_min, original_max = -1, 19\n",
    "    target_min, target_max = 1, 8\n",
    "\n",
    "    # Calculate the total number of values in each range\n",
    "    original_range = original_max - original_min\n",
    "    target_range = target_max - target_min\n",
    "\n",
    "    # Scale the original value to the target range\n",
    "    scaled_value = ((skill - original_min) / original_range) * target_range + target_min\n",
    "\n",
    "    # Round and return the scaled value, making sure it stays within the target range\n",
    "    return str(min(target_max, max(target_min, round(scaled_value))))\n",
    "\n",
    "def transform_row(row):\n",
    "    # Split and get the number from player_one and player_two\n",
    "    player_one_number = int(row['player_one'].split()[1])\n",
    "    player_two_number = int(row['player_two'].split()[1])\n",
    "\n",
    "    # Apply map_value to these numbers\n",
    "    mapped_player_one = map_skill_to_int(player_one_number)\n",
    "    mapped_player_two = map_skill_to_int(player_two_number)\n",
    "\n",
    "    transcript = row['transcript'].split('\\n\\n')[1]\n",
    "\n",
    "    # Prepend the transcript with the formatted string\n",
    "    row['transcript'] = f\"[{mapped_player_one},{mapped_player_two}]{transcript}\"\n",
    "\n",
    "    return row\n",
    "\n",
    "# skills = range(-2,21)\n",
    "\n",
    "# for skill in skills:\n",
    "#     print(skill, map_skill_to_int(skill))\n",
    "# df_subset = df.sample(10)\n",
    "# df_transformed = df_subset.apply(transform_row, axis=1)\n",
    "# print(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc36faf17cd409b88a3940114cc1772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(input_file)\n",
    "df = df.parallel_apply(transform_row, axis=1)\n",
    "df['transcript'].to_csv('input_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 532/10000 [00:45<13:26, 11.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m stockfish_process\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39minput_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtranscript\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: insert_centipawn(x, depth\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, frequency\u001b[39m=\u001b[39;49m\u001b[39m0.03\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m terminate_stockfish()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# your_list = range(-800, 800, 40)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# mapped_list = [map_eval_to_int({\"type\":\"cp\", \"value\":x}) for x in your_list]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39m# for i in range(len(mapped_list)):\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39m#     print(mapped_list[i], your_list[i])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/tqdm/std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    921\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4755\u001b[0m         func,\n\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1289\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/tqdm/std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    910\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m stockfish_process\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39minput_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: insert_centipawn(x, depth\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, frequency\u001b[39m=\u001b[39;49m\u001b[39m0.03\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m terminate_stockfish()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# your_list = range(-800, 800, 40)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# mapped_list = [map_eval_to_int({\"type\":\"cp\", \"value\":x}) for x in your_list]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39m# for i in range(len(mapped_list)):\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39m#     print(mapped_list[i], your_list[i])\u001b[39;00m\n",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     input_queue\u001b[39m.\u001b[39mput((board\u001b[39m.\u001b[39mfen(), move))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     eval_move, evaluation \u001b[39m=\u001b[39m output_queue\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39massert\u001b[39;00m eval_move \u001b[39m==\u001b[39m move  \u001b[39m# Ensure correct correspondence\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(map_eval_to_int(evaluation)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m block \u001b[39mand\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sem\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m maxlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m maxlength \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnegative maxlength\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes(maxlength)\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import chess\n",
    "from stockfish import Stockfish\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "def terminate_stockfish():\n",
    "    input_queue.put((\"EXIT\", None))\n",
    "    stockfish_process.join()\n",
    "\n",
    "def stockfish_worker(input_queue, output_queue):\n",
    "    mac_path = \"stockfish\"\n",
    "    linux_path = \"/usr/games/stockfish\"\n",
    "    # self._engine = chess.engine.SimpleEngine.popen_uci(linux_path)\n",
    "    stockfish = Stockfish(mac_path)\n",
    "    stockfish.set_depth(10) \n",
    "    while True:\n",
    "        fen, move = input_queue.get()\n",
    "        if fen == \"EXIT\":\n",
    "            break\n",
    "        stockfish.set_fen_position(fen)\n",
    "        evaluation = stockfish.get_evaluation()\n",
    "        output_queue.put((move, evaluation))\n",
    "\n",
    "# Step 3: Randomly insert centipawn\n",
    "def map_eval_to_int(evaluation: dict) -> int:\n",
    "    if evaluation['type'] == 'mate':\n",
    "        # for example, 3 would be mate in 3 for white, -2 is mate in 2 for black\n",
    "        if evaluation['value'] > 0:\n",
    "            return 9\n",
    "        else:\n",
    "            return -9\n",
    "    \n",
    "    # if not mate, must be centipawn advantage\n",
    "    value = evaluation['value']\n",
    "\n",
    "    if value > 700:\n",
    "        return 8\n",
    "    elif value < -700:\n",
    "        return -8\n",
    "    original_min, original_max = -700, 700\n",
    "    target_min, target_max = -7, 7\n",
    "\n",
    "    # Calculate the total number of values in each range\n",
    "    original_range = original_max - original_min\n",
    "    target_range = target_max - target_min\n",
    "\n",
    "    # Scale the original value to the target range\n",
    "    scaled_value = ((value - original_min) / original_range) * target_range + target_min\n",
    "\n",
    "    # Round and return the scaled value, making sure it stays within the target range\n",
    "    return str(min(target_max, max(target_min, round(scaled_value))))\n",
    "    \n",
    "def game_over_to_value(board_result: str) -> int:\n",
    "    result_map = {\"1-0\": 9, \"0-1\": -9, \"1/2-1/2\": 0}\n",
    "    return result_map[board_result]\n",
    "\n",
    "def insert_centipawn(moves_string: str, depth: int = 9, frequency: float = 0.03) -> str:\n",
    "    # Create a new board\n",
    "    board = chess.Board()\n",
    "\n",
    "    \n",
    "    eval_results = []\n",
    "\n",
    "    new_moves_string = \"\"\n",
    "\n",
    "    # Apply each move to the board\n",
    "    for move in moves_string.split():\n",
    "        # Skip move numbers\n",
    "        if '.' in move:\n",
    "            board.push_san(move.split(\".\")[1])\n",
    "        else:\n",
    "            board.push_san(move)\n",
    "\n",
    "        new_moves_string += move + \" \"\n",
    "        if random.random() < frequency:\n",
    "            # Check for checkmate or draw\n",
    "            eval = \"\"\n",
    "            if board.result() != \"*\":\n",
    "                # eval_results.append(game_over_to_value(board.result()))\n",
    "                eval = \" <\" + str(game_over_to_value(board.result())) + \"> \"\n",
    "            else:\n",
    "                input_queue.put((board.fen(), move))\n",
    "                eval_move, evaluation = output_queue.get()\n",
    "                assert eval_move == move  # Ensure correct correspondence\n",
    "                eval = \"<\" + str(map_eval_to_int(evaluation)) + \" \"\n",
    "                new_moves_string += eval\n",
    "\n",
    "            new_moves_string += eval\n",
    "\n",
    "    # Display the board position after the moves\n",
    "    # print(board.result())\n",
    "\n",
    "    # return eval_results\n",
    "    return new_moves_string\n",
    "\n",
    "tqdm.pandas()\n",
    "input_queue = multiprocessing.Queue()\n",
    "output_queue = multiprocessing.Queue()\n",
    "\n",
    "stockfish_process = multiprocessing.Process(target=stockfish_worker, args=(input_queue, output_queue))\n",
    "stockfish_process.start()\n",
    "\n",
    "df = pd.read_csv('input_dataset.csv')\n",
    "df['transcript'] = df['transcript'].progress_apply(lambda x: insert_centipawn(x, depth=10, frequency=0.03))\n",
    "terminate_stockfish()\n",
    "\n",
    "# your_list = range(-800, 800, 40)\n",
    "# mapped_list = [map_eval_to_int({\"type\":\"cp\", \"value\":x}) for x in your_list]\n",
    "\n",
    "# for i in range(len(mapped_list)):\n",
    "#     print(mapped_list[i], your_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminate_stockfish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing centipawn\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df = pd.read_csv(input_file)\n",
    "# index = 1\n",
    "# selected_rows = df.groupby('result').first().reset_index()\n",
    "# selected_rows = selected_rows.apply(transform_row, axis=1)\n",
    "# print(selected_rows.iloc[index]['transcript'])\n",
    "# selected_rows['transcript'] = selected_rows['transcript'].apply(lambda x: insert_centipawn(x, depth=10))\n",
    "\n",
    "\n",
    "# For graphing results\n",
    "\n",
    "# print(selected_rows.iloc[index]['transcript'])\n",
    "# print(selected_rows.iloc[index])\n",
    "\n",
    "# new_moves = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=10)\n",
    "# print(new_moves)\n",
    "\n",
    "# Make insert centipawn return list to graph evals\n",
    "# ten = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=10)\n",
    "# nine = insert_centipawn(selected_rows.iloc[index]['transcript'], depth=9)\n",
    "# ten = [int(i) for i in ten]\n",
    "# nine = [int(i) for i in nine]\n",
    "\n",
    "\n",
    "# plt.plot(ten, label='ten', color='blue')\n",
    "# plt.plot(nine, color='red')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3023/10000 [00:09<00:21, 325.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m stockfish\u001b[39m.\u001b[39mset_depth(\u001b[39m1\u001b[39m) \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39minput_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtranscript\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: insert_centipawn(x, depth\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, frequency\u001b[39m=\u001b[39;49m\u001b[39m0.03\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/tqdm/std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    921\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4755\u001b[0m         func,\n\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1289\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/tqdm/std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    910\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m stockfish\u001b[39m.\u001b[39mset_depth(\u001b[39m1\u001b[39m) \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39minput_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: insert_centipawn(x, depth\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, frequency\u001b[39m=\u001b[39;49m\u001b[39m0.03\u001b[39;49m))\n",
      "\u001b[1;32m/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m         board\u001b[39m.\u001b[39mpush_san(move\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m         board\u001b[39m.\u001b[39;49mpush_san(move)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     new_moves_string \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m move \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m# if random.random() < frequency:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m#     # Check for checkmate or draw\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m#     eval = \"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvm-37-ee.eic.galois.com/home/adamk/github_chess_gpt_eval/logs/improved_batching.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# return eval_results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/chess/__init__.py:3105\u001b[0m, in \u001b[0;36mBoard.push_san\u001b[0;34m(self, san)\u001b[0m\n\u001b[1;32m   3091\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpush_san\u001b[39m(\u001b[39mself\u001b[39m, san: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Move:\n\u001b[1;32m   3092\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[39m    Parses a move in standard algebraic notation, makes the move and puts\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \u001b[39m    it onto the move stack.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3103\u001b[0m \u001b[39m        - :exc:`AmbiguousMoveError` if the SAN is ambiguous.\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3105\u001b[0m     move \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_san(san)\n\u001b[1;32m   3106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush(move)\n\u001b[1;32m   3107\u001b[0m     \u001b[39mreturn\u001b[39;00m move\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/chess/__init__.py:3077\u001b[0m, in \u001b[0;36mBoard.parse_san\u001b[0;34m(self, san)\u001b[0m\n\u001b[1;32m   3075\u001b[0m \u001b[39m# Match legal moves.\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m matched_move \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3077\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_legal_moves(from_mask, to_mask):\n\u001b[1;32m   3078\u001b[0m     \u001b[39mif\u001b[39;00m move\u001b[39m.\u001b[39mpromotion \u001b[39m!=\u001b[39m promotion:\n\u001b[1;32m   3079\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.10/site-packages/chess/__init__.py:3589\u001b[0m, in \u001b[0;36mBoard.generate_legal_moves\u001b[0;34m(self, from_mask, to_mask)\u001b[0m\n\u001b[1;32m   3587\u001b[0m \u001b[39mif\u001b[39;00m king_mask:\n\u001b[1;32m   3588\u001b[0m     king \u001b[39m=\u001b[39m msb(king_mask)\n\u001b[0;32m-> 3589\u001b[0m     blockers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slider_blockers(king)\n\u001b[1;32m   3590\u001b[0m     checkers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattackers_mask(\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturn, king)\n\u001b[1;32m   3591\u001b[0m     \u001b[39mif\u001b[39;00m checkers:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text: str) -> list[str]:\n",
    "    full_chunk_size = 1023\n",
    "    header_size = 5\n",
    "    chunk_size = full_chunk_size - header_size\n",
    "\n",
    "    length = len(text)\n",
    "\n",
    "    if length < full_chunk_size:\n",
    "        return text\n",
    "    \n",
    "    header = text[:header_size]\n",
    "\n",
    "    text = text[header_size:]\n",
    "    length = len(text)\n",
    "\n",
    "    # Calculate the number of chunks needed\n",
    "    num_chunks = (length + chunk_size - 1) // chunk_size\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start_index = length - (i + 1) * chunk_size\n",
    "        end_index = length - i * chunk_size\n",
    "        start_index = max(start_index, 0)  # Ensure the start index is not negative\n",
    "\n",
    "        chunk = header + text[start_index:end_index]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Reverse the list to maintain the chronological order\n",
    "    chunks.reverse()\n",
    "\n",
    "    if len(chunks[0]) < 511:\n",
    "        chunks.pop(0)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e768cfd8746e7869a19e8e31640b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['transcript'] = df['transcript'].parallel_apply(transform_text)\n",
    "df = df.explode('transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10344\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.to_csv('input_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # For testing transform text\n",
    "\n",
    "# df = pd.read_csv(input_file)\n",
    "# df = df.apply(transform_row, axis=1)\n",
    "\n",
    "# filtered_df = df[df['transcript'].apply(len) > 2500]\n",
    "\n",
    "# text = filtered_df.iloc[0]['transcript']\n",
    "\n",
    "# print(len(df))\n",
    "# print(len(filtered_df))\n",
    "# print(len(filtered_df)/len(df))\n",
    "\n",
    "# chunks = transform_text(text)\n",
    "# text1 = chunks[0]\n",
    "\n",
    "# for chunk in chunks:\n",
    "#     print(len(chunk))\n",
    "#     print(chunk)\n",
    "\n",
    "# chunks2 = transform_text(text1)\n",
    "# print(len(chunks2))\n",
    "# print(chunks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f625f4a600e47ed81c02ff39272b942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1293), Label(value='0 / 1293'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sort df by transcript length for batching\n",
    "\n",
    "df = pd.read_csv('input_dataset.csv', usecols=['transcript'])\n",
    "df['length'] = df['transcript'].parallel_apply(len)\n",
    "\n",
    "df.sort_values(by='length', inplace=True)\n",
    "# df.to_csv('input_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = input_file.replace('.csv', '_blocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10344/10344 [00:00<00:00, 386349.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import random\n",
    "\n",
    "# Read the CSV file\n",
    "# df = pd.read_csv('input_dataset.csv')\n",
    "\n",
    "# Prepare the new dataset for blocks\n",
    "blocks = []\n",
    "remaining_games = deque(df['transcript'].tolist())  # Use deque for efficient pops from the left\n",
    "\n",
    "original_length = len(remaining_games)  # Store the original length\n",
    "\n",
    "# Block size limit\n",
    "block_size = 1024\n",
    "\n",
    "# Initialize the progress bar\n",
    "with tqdm(total=original_length, desc=\"Processing\") as pbar:\n",
    "    while remaining_games:\n",
    "        block = ';'\n",
    "        # Select the next game\n",
    "        next_game = remaining_games.pop()\n",
    "        block += next_game\n",
    "        while len(block) < block_size and remaining_games:\n",
    "            # if len(df) > 21:\n",
    "            #     random_idx = random.randint(0, 20)\n",
    "            #     next_game = remaining_games[random_idx]\n",
    "            #     remaining_games[random_idx] = \"\"\n",
    "            # else:\n",
    "            next_game = remaining_games.popleft()\n",
    "            block += ';' + next_game\n",
    "            if len(block) > block_size:\n",
    "                # If the game makes the block too long, re-add it to the dataset\n",
    "                if len(remaining_games) > 100:\n",
    "                    remaining_games.insert(99, next_game)\n",
    "                else:\n",
    "                    break\n",
    "                break\n",
    "\n",
    "        if len(block) >= block_size:\n",
    "            # Add the block to the blocks list\n",
    "            blocks.append(block[:block_size])\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(original_length - len(remaining_games) - pbar.n)\n",
    "\n",
    "# Create a new DataFrame for the blocks\n",
    "blocks_df = pd.DataFrame(blocks, columns=['transcript'])\n",
    "\n",
    "# Save the blocks to a new CSV file\n",
    "blocks_df.to_csv(output_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7199.0\n",
      "mean     1024.0\n",
      "std         0.0\n",
      "min      1024.0\n",
      "25%      1024.0\n",
      "50%      1024.0\n",
      "75%      1024.0\n",
      "max      1024.0\n",
      "Name: length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(output_filename)\n",
    "df['length'] = df['transcript'].apply(len)\n",
    "print(df['length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Shuffle dataset\n",
    "\n",
    "temp_output_filename = \"full2_dataset.csv\"\n",
    "# output_filename = temp_output_filename\n",
    "\n",
    "df = pd.read_csv(output_filename)\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the shuffled DataFrame to the same CSV file\n",
    "df_shuffled.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
