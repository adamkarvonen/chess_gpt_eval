{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('full2_dataset.csv')\n",
    "\n",
    "# Concatenate 'transcript' column\n",
    "concatenated_transcripts = ''.join(df['transcript'].astype(str))\n",
    "\n",
    "# Write to 'input.txt'\n",
    "with open('5gb_batch_input.txt', 'w') as file:\n",
    "    file.write(concatenated_transcripts)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Concatenated transcripts written to input.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated transcripts written to input.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 10000  # You can adjust this size based on your system's capability\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('5gb_batch_input.txt', 'w') as file:\n",
    "    # Read the CSV file in chunks\n",
    "    for chunk in pd.read_csv('full2_dataset.csv', chunksize=chunk_size):\n",
    "        # Concatenate 'transcript' column in the current chunk\n",
    "        concatenated_transcripts = ''.join(chunk['transcript'].astype(str))\n",
    "        # Write the concatenated string to the text file\n",
    "        file.write(concatenated_transcripts)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Concatenated transcripts written to input.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells: 3070539\n",
      "Number of unique starting sequences (100 chars): 2518374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_cells(file_path: str) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of cells in the 'transcript' column of the CSV file.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    int: Number of cells in the 'transcript' column.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    chunksize = 10 ** 5  # Adjust chunksize based on your memory capacity\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        count += chunk['transcript'].size\n",
    "    return count\n",
    "\n",
    "def collect_unique_starts(file_path: str, num_chars: int) -> set:\n",
    "    \"\"\"\n",
    "    Collects the first 'num_chars' characters of each cell in the 'transcript' column.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file.\n",
    "    num_chars (int): Number of characters to collect from the start of each cell.\n",
    "\n",
    "    Returns:\n",
    "    set: A set containing unique starting strings of specified length.\n",
    "    \"\"\"\n",
    "    unique_starts = set()\n",
    "    chunksize = 10 ** 5  # Adjust chunksize based on your memory capacity\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        starts = chunk['transcript'].str[:num_chars]\n",
    "        unique_starts.update(starts)\n",
    "    return unique_starts\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"full_dataset.csv\"\n",
    "cell_count = count_cells(file_path)\n",
    "unique_starting_chars = collect_unique_starts(file_path, 100)\n",
    "\n",
    "print(f\"Number of cells: {cell_count}\")\n",
    "print(f\"Number of unique starting sequences (100 chars): {len(unique_starting_chars)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells: 3070539\n",
      "Number of unique starting sequences (100 chars): 2664468\n"
     ]
    }
   ],
   "source": [
    "unique_starting_chars = collect_unique_starts(file_path, 200)\n",
    "\n",
    "print(f\"Number of cells: {cell_count}\")\n",
    "print(f\"Number of unique starting sequences (100 chars): {len(unique_starting_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells: 3070539\n",
      "Number of unique starting sequences (550 chars): 2715568\n"
     ]
    }
   ],
   "source": [
    "num_chars = 550\n",
    "unique_starting_chars = collect_unique_starts(file_path, num_chars)\n",
    "\n",
    "print(f\"Number of cells: {cell_count}\")\n",
    "print(f\"Number of unique starting sequences ({num_chars} chars): {len(unique_starting_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells: 3070539\n",
      "Number of unique starting sequences (1000 chars): 3033321\n"
     ]
    }
   ],
   "source": [
    "num_chars = 1000\n",
    "unique_starting_chars = collect_unique_starts(file_path, num_chars)\n",
    "\n",
    "print(f\"Number of cells: {cell_count}\")\n",
    "print(f\"Number of unique starting sequences ({num_chars} chars): {len(unique_starting_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells: 3070539\n",
      "Number of unique starting sequences (300 chars): 2664741\n"
     ]
    }
   ],
   "source": [
    "num_chars = 300\n",
    "unique_starting_chars = collect_unique_starts(file_path, num_chars)\n",
    "\n",
    "print(f\"Number of cells: {cell_count}\")\n",
    "print(f\"Number of unique starting sequences ({num_chars} chars): {len(unique_starting_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8667009277524239\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_starting_chars) / cell_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[';1.e4 c6 2.d4 d5 3.e5 e6 4.Nf3 Nd7 5.Be2 h6 6.O-O a6 7.c4 Ne7 8.Nc3 Ng6 9.Bd3 Nh4 10.Nxh4 Qxh4 11.f4 dxc4 12.Bxc4 Qd8 13.Be3 b5 14.Bd3 Bb4 15.Qg4 g6 16.Bxg6 Nf8 17.Be4 Bb7 18.f5 Rb8 19.fxe6 Qc8 20.exf7+ Kd8 21.Qg7 Qc7 22.Qxh8 h5 23.Bh6 Qe7 24.Bg5 Qxg5 25.Qf6+ Qxf6 26.Rxf6 Be7 27.Rh6 Rc8 28.Rh8 Kc7 2']\n"
     ]
    }
   ],
   "source": [
    "test = [\"\"\";1.e4 c6 2.d4 d5 3.e5 e6 4.Nf3 Nd7 5.Be2 h6 6.O-O a6 7.c4 Ne7 8.Nc3 Ng6 9.Bd3 Nh4 10.Nxh4 Qxh4 11.f4 dxc4 12.Bxc4 Qd8 13.Be3 b5 14.Bd3 Bb4 15.Qg4 g6 16.Bxg6 Nf8 17.Be4 Bb7 18.f5 Rb8 19.fxe6 Qc8 20.exf7+ Kd8 21.Qg7 Qc7 22.Qxh8 h5 23.Bh6 Qe7 24.Bg5 Qxg5 25.Qf6+ Qxf6 26.Rxf6 Be7 27.Rh6 Rc8 28.Rh8 Kc7 29.Rf1 Bg5 30.Rf6 Rd8 31.Ne2 b4 32.Kf2 Bxf6 33.exf6 h4 34.Ke3\"\"\",\n",
    "        \"\"\"\"\"\"]\n",
    "test_games = []\n",
    "for i in range(len(test)):\n",
    "    if len(test[i]) > 300:\n",
    "        test_games.append(test[i][:300])\n",
    "print(test_games)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
